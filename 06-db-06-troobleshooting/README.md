# Домашнее задание к занятию 6. «Troubleshooting» - Леонид Хорошев

## Задача 1

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

1. Cписок операций, которые вы будете производить для остановки запроса пользователя:
- переходим в оболочку mongodb;
```
mongosh
```
- запрашиваем текущие выполняемые операции;
```
db.currentOp()
```
- находим opid операции, которую нужно прервать:
![Alt text](https://github.com/LeonidKhoroshev/bd-dev-homeworks/blob/main/06-db-06-troobleshooting/trsh/trsh1.png)
Тут необходимо сделать небольшое примечание - для выполнения домашнего задания установлена [MongoDB 7.0 Community Edition](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/) на виртуальную маштину под управлением Centos7, большие базы данных я не нашел, поэтому работал с дефолтными:
![Alt text](https://github.com/LeonidKhoroshev/bd-dev-homeworks/blob/main/06-db-06-troobleshooting/trsh/trsh2.png) Сложных CRUD-операций тут не много, поэтому для удаления выбрана операция с рандомным opid (для наглядности).
- прерываем операцию:
```
db.killOp(1445)
```
![Alt text](https://github.com/LeonidKhoroshev/bd-dev-homeworks/blob/main/06-db-06-troobleshooting/trsh/trsh3.png) 

2. Предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB:
   - самое главное - выявлять долгие запросы не через канал поддержки (когда уже поступают жалобы), а через [мониторинг] (https://www.mongodb.com/docs/manual/administration/monitoring/) или Prometheus;
   - смотрим через explain план выполнения запроса;
   - далее необходимо оптимизировать зависающий запрос, а именно:
     - выводить в запросе только те поля, которые необходимы в дальнейшей работы;
     - использовать опцию lean() в запросе, она позволяет пропустить создание экземпляра полного документа и тем, самым сократить время обратотки запроса;
     - использовать индексы (позволяют упорядочить данные по определенному полю, что впоследствии ускорит поиск).

Дополнительно в открытых источниках много информации об оптимизации запросов через пагинацию (постраничный вывод результатов запроса), распараллеливание запросов и так далее. Поскольку опыт работы даже с MongoDB даже в рамках данного курса отсутствует, то углубляться дальше в данную тему сложно.
   


## Задача 2

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?

Наиболее вероятная причина - переполнение памяти. Redis однопоточный. Все команды являются атомарными. Пока команда выполняется, никакая другая команда не может быть выполнена.

Для решения указанной проблемы можно рассмотреть несколько вариантов:
 - уменьшить срок хранения пар ключ-значение для более быстрой отчистки памяти;
 - использование функции "ленивого удаления" (redis сначала проверит, истек ли срок действия ключа, если он истек, тогда redis удалит ключ);
 - использование slowlog для оптимизации команд, отнимающих много времени (для медленный запросов есть два важных элемента конфигурации `slowlog-log-slower-than` (используется для установки времени оценки медленного запроса, то есть команды, превышающие этот элемент конфигурации, будут обрабатываться как медленные операции и записываться в соответствующий журнал, а также `slowlog-max-len`(используется для настройки максимального количества записей в журнале медленных запросов);
 - ограничение объема памяти Redis (параметр конфигурации `maxmemory` в стандартных настройках закомментирован, и когда память заканчивается, это блокирует запись данных в Redis Следовательно, нам нужно ограничить размер памяти Redis до фиксированного значения. Когда операция Redis достигает этого значения, [срабатывает стратегия исключения памяти](https://redis.io/docs/reference/eviction/)).
    
## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

По условиям задания MySQL используется в геоинформационной системе. Такие системы хаарктеризуются огромными наборами данных, следовательно наиболее вероятная причина - нехватка ресурсов сервера для корректной работы системы (кончилась память).

Какие пути решения этой проблемы вы можете предложить?

Самый общий путь - горизонтальное шаридирование таблиц нашей базы данных на несколько нод. Также в настройках базы данных можно ограничить колическтво подключений к базе данных, указав параметр `max_connections` в файле `my.cnf`. Еще можно откорректировать значение `max_allowed_packet` (максимальный размер сетевого протокола MySQL, который может быть прочитан или создан сервером). Как правило он установлен на уровне 16 Мб, его можно увеличить, например, до 32 Мб.

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

`postmaster invoked oom-killer` говорит о проблеме нехватки памяти. Так может происходить по следующим причинам:
- некорректные настройки параметров в `postgresql.conf`, связанных с распределением серверных ресурсов для СУБД - `shared_buffer` (параметр устанавливает, сколько выделенной памяти будет использоваться для кеширования), `wal_buffers` (размер журнала предзаписи и т.д.);
- слишком большое количество разрешенных подключений (параметр `max_connections`).

Также не стоит забывать об ограниченности ресурсов сервера и разворачивать базы данных для геоинформационных систем в кластере, используя инструменты шардирования и реплицирования.

Как бы вы решили эту проблему?

Данная проблема решается переносом базы данных с одного сервера в отказоустойчивый кластер (практика показывает, что в PostgresQL данная функция реализована удобнее, чем в MySQL), а также корректировкой вышеупомянутых параметров в файле `postgresql.conf` (`shared_buffer`, `wal_buffers`, `max_connections`).

---


